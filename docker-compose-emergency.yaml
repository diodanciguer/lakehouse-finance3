# DOCKER COMPOSE EMERGENCIAL - SEM PATCHES
# Use apenas se o principal não funcionar

x-airflow-common: &airflow-common
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:3.0.6}
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres3:5432/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres3:5432/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://redis3:6379/0
    
    # FORÇA URL PÚBLICA
    AIRFLOW__WEBSERVER__BASE_URL: https://lakehouse-finance3-airflow3.hjbbqx.easypanel.host
    AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: True
    
    # Secrets
    AIRFLOW__API__SECRET_KEY: ${AIRFLOW__API__SECRET_KEY:-change-this-to-a-long-random-string}
    AIRFLOW_SECRET_KEY: ${AIRFLOW_SECRET_KEY:-change-this-to-a-long-random-string}
    
    # Auth manager FAB
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__API__AUTH_BACKENDS: airflow.providers.fab.auth_manager.api.auth.backend.session.SessionAuthBackend
    
    # Provider FAB
    _PIP_ADDITIONAL_REQUIREMENTS: apache-airflow-providers-fab
    
  user: "${AIRFLOW_UID:-50000}:0"
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
  depends_on:
    postgres3:
      condition: service_healthy
    redis3:
      condition: service_healthy

services:
  postgres3:
    image: postgres:16
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow  
      POSTGRES_DB: airflow
    volumes:
      - postgres3-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  redis3:
    image: redis:7-alpine
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  airflow3-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -e
        echo ">>> Migrando DB..."
        airflow db migrate
        echo ">>> Criando usuário padrão..."
        airflow users create \
          --role Admin \
          --username airflow \
          --password airflow \
          --email airflow@example.com \
          --firstname Admin --lastname User || echo "Usuário já existe"
    restart: "no"

  airflow3-api-server:
    <<: *airflow-common
    environment:
      <<: *airflow-common-env
      # FORÇA BASE URL SEM PATCHES
      AIRFLOW__WEBSERVER__BASE_URL: https://lakehouse-finance3-airflow3.hjbbqx.easypanel.host
    # COMANDO SIMPLES - SEM PATCHES
    command: ["airflow", "api-server", "--port", "8080", "--hostname", "0.0.0.0"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/health >/dev/null"]
      interval: 10s
      timeout: 10s
      retries: 30
    restart: unless-stopped

  airflow3-scheduler:
    <<: *airflow-common
    command: ["airflow", "scheduler"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    restart: unless-stopped

volumes:
  postgres3-data:
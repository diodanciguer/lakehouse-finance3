# docker compose v2+ (sem "version")
# Airflow 3.0.6 com CeleryExecutor e API Server
# Sufixo "3" para não colidir com seu Airflow 2.x

x-airflow-common: &airflow-common
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:3.0.6}
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres3:5432/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres3:5432/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://redis3:6379/0

    # Webserver por trás de proxy + domínio público
    AIRFLOW__WEBSERVER__BASE_URL: https://lakehouse-finance3-airflow3.hjbbqx.easypanel.host
    AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: True
    AIRFLOW__WEBSERVER__USE_FORWARDED_FOR: True
    AIRFLOW__WEBSERVER__WEB_SERVER_SSL_CERT: ""
    AIRFLOW__WEBSERVER__WEB_SERVER_SSL_KEY: ""
    
    # Configurações críticas do proxy reverso
    AIRFLOW__WEBSERVER__PROXY_FIX_X_FOR: ${AIRFLOW__WEBSERVER__PROXY_FIX_X_FOR:-1}
    AIRFLOW__WEBSERVER__PROXY_FIX_X_PROTO: ${AIRFLOW__WEBSERVER__PROXY_FIX_X_PROTO:-1}
    AIRFLOW__WEBSERVER__PROXY_FIX_X_HOST: ${AIRFLOW__WEBSERVER__PROXY_FIX_X_HOST:-1}
    AIRFLOW__WEBSERVER__PROXY_FIX_X_PORT: ${AIRFLOW__WEBSERVER__PROXY_FIX_X_PORT:-1}
    AIRFLOW__WEBSERVER__PROXY_FIX_X_PREFIX: ${AIRFLOW__WEBSERVER__PROXY_FIX_X_PREFIX:-1}
    
    # Restringe hosts aceitos pela UI
    AIRFLOW__WEBSERVER__ALLOWED_HOSTS: ${AIRFLOW__WEBSERVER__ALLOWED_HOSTS:-lakehouse-finance3-airflow3.hjbbqx.easypanel.host}

    # Secrets (API e sessão) - CHAVES FIXAS para persistência
    AIRFLOW__API__SECRET_KEY: lakehouse-finance3-airflow3-secret-key-2024-fixed
    AIRFLOW_SECRET_KEY: lakehouse-finance3-airflow3-secret-key-2024-fixed
    
    # JWT secrets para comunicação entre componentes (Airflow 3)
#    AIRFLOW__EXECUTION_API__JWT_SECRET: uEND50NXiA1bt3HR+oVkKQ==
#    AIRFLOW__EXECUTION_API__JWT_ALGORITHM: HS512
#    AIRFLOW__EXECUTION_API__JWT_AUDIENCE: urn:airflow.apache.org:task
#    AIRFLOW__EXECUTION_API__JWT_ISSUER: airflow.apache.org

    # Configurações adicionais do Execution API para resolver JWT auth
    AIRFLOW__TASK_EXECUTION__ENDPOINT_URL: http://airflow3-api-server:8080/execution
    AIRFLOW__API_FASTAPI__CSRF_PROTECT: false
    
    # Configurações de sessão persistente (Airflow 3 compatível)
    AIRFLOW__WEBSERVER__SESSION_TIMEOUT_MINUTES: 525600  # 1 ano
    AIRFLOW__WEBSERVER__COOKIE_HTTPONLY: True
    AIRFLOW__WEBSERVER__COOKIE_SECURE: False  # Mudado para False - conflito com proxy
    AIRFLOW__WEBSERVER__COOKIE_SAMESITE: Lax
    
    # Configurações de autenticação para Airflow 3
    AIRFLOW__WEBSERVER__ENABLE_WTF_CSRF: False
    AIRFLOW__WEBSERVER__SECRET_KEY: lakehouse-finance3-webserver-secret-key-2024-fixed

    # Fuso horário
    AIRFLOW__CORE__DEFAULT_TIMEZONE: ${TZ:-America/Sao_Paulo}
    TZ: ${TZ:-America/Sao_Paulo}

    # Fernet key FIXA para persistência de dados (senhas, conexões)
    AIRFLOW__CORE__FERNET_KEY: lakehouse-finance3-fernet-key-2024-fixed-abcd1234567890==

    # Auth manager FAB (UI de login)
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager

    # Provider FAB para UI/API baseada em sessão
    AIRFLOW__API__AUTH_BACKENDS: airflow.providers.fab.auth_manager.api.auth.backend.session.SessionAuthBackend
    
    # Configurações FAB específicas para Airflow 3
    AIRFLOW__FAB__BASE_TEMPLATE: airflow/main.html
    AIRFLOW__FAB__AUTH_TYPE: AUTH_DB
    AIRFLOW__FAB__AUTH_ROLE_ADMIN: Admin
    AIRFLOW__FAB__AUTH_ROLE_PUBLIC: Public
    AIRFLOW__FAB__APP_THEME: "bootstrap-theme.css"

    # Configurações de logging para Airflow 3
    AIRFLOW__LOGGING__REMOTE_LOGGING: False
    AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
    AIRFLOW__LOGGING__DAG_PROCESSOR_LOG_TARGET: /opt/airflow/logs/dag_processor
    AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
    AIRFLOW__LOGGING__LOG_FORMAT: "[%%(asctime)s] {%%(filename)s:%%(lineno)d} %%(levelname)s - %%(message)s"
    AIRFLOW__LOGGING__SIMPLE_LOG_FORMAT: "[%%(asctime)s] %%(levelname)s - %%(message)s"
    
    # Task logging específico para Airflow 3
    AIRFLOW__LOGGING__TASK_LOG_PREFIX_TEMPLATE: ""
    
    # Configurações de webserver logging para exibir logs na UI
    AIRFLOW__WEBSERVER__LOG_FETCH_TIMEOUT_SEC: 5
    AIRFLOW__WEBSERVER__LOG_FETCH_DELAY_SEC: 2
    AIRFLOW__WEBSERVER__LOG_AUTO_TAILING_OFFSET: 30
    AIRFLOW__WEBSERVER__LOG_ANIMATION_SPEED: 1000

    # Providers necessários para funcionalidades específicas
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-apache-airflow-providers-postgres apache-airflow-providers-fab}

    # Evita proxy e força tráfego direto entre containers
    NO_PROXY: ${NO_PROXY:-localhost,127.0.0.1,airflow3-api-server,postgres3,redis3}
  user: "${AIRFLOW_UID:-50000}:0"
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
    - ./entrypoint.sh:/opt/airflow/entrypoint.sh
  depends_on:
    postgres3:
      condition: service_healthy
    redis3:
      condition: service_healthy

services:
  postgres3:
    image: postgres:16
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres3-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  redis3:
    image: redis:7-alpine
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  # Roda uma vez: migra DB e cria admin se não existir (usa _AIRFLOW_WWW_USER_* do Easypanel)
  airflow3-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -e
        echo ">>> Migrando DB..."
        airflow db migrate

        if [ -z "$_AIRFLOW_WWW_USER_USERNAME" ] || [ -z "$_AIRFLOW_WWW_USER_PASSWORD" ] || [ -z "$_AIRFLOW_WWW_USER_EMAIL" ]; then
          echo "ERRO: variáveis _AIRFLOW_WWW_USER_* não definidas. Abortando criação do usuário."
          exit 1
        fi

        echo ">>> Verificando se o usuário ${_AIRFLOW_WWW_USER_USERNAME} existe..."
        if ! airflow users list --output yaml | grep -q " username: ${_AIRFLOW_WWW_USER_USERNAME}$"; then
          echo ">>> Criando usuário admin ${_AIRFLOW_WWW_USER_USERNAME}..."
          airflow users create \
            --role Admin \
            --username "$_AIRFLOW_WWW_USER_USERNAME" \
            --password "$_AIRFLOW_WWW_USER_PASSWORD" \
            --email "$_AIRFLOW_WWW_USER_EMAIL" \
            --firstname Admin --lastname User
        else
          echo ">>> Usuário já existe. Pulando criação."
        fi
    restart: "no"

  airflow3-api-server:
    <<: *airflow-common
    # Configurações específicas do API server
    environment:
      <<: *airflow-common-env
      # Força o API server a usar a URL pública - SEM fallback
      AIRFLOW__WEBSERVER__BASE_URL: https://lakehouse-finance3-airflow3.hjbbqx.easypanel.host
      # Força SSL/HTTPS
      AIRFLOW__WEBSERVER__FORCE_SECURE: "True"
      # Desabilita redirects internos
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "False"
      # Força host e esquema corretos
      FLASK_ENV: production
      PREFERRED_URL_SCHEME: https
      SERVER_NAME: lakehouse-finance3-airflow3.hjbbqx.easypanel.host
      # Força conteúdo a ser servido via HTTPS
      AIRFLOW__WEBSERVER__X_FRAME_OPTIONS: SAMEORIGIN
    # Comando corrigido - api-server não aceita --hostname
    command: 
      - bash
      - -c
      - |
        set -e
        echo "[INFO] Iniciando Airflow 3.0.6 API Server..."
        
        # Aplicar patches (silencioso)
        export PYTHONPATH="/opt/airflow/config:$$PYTHONPATH"
        python3 /opt/airflow/config/init_patches.py > /dev/null 2>&1
        
        echo "[INFO] Patches aplicados, iniciando servidor..."
        exec airflow api-server --port 8080
    # Não expor portas no Easypanel - o proxy interno cuida disso
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/ >/dev/null"]
      interval: 10s
      timeout: 10s
      retries: 30
    restart: unless-stopped

  airflow3-scheduler:
    <<: *airflow-common
    environment:
      <<: *airflow-common-env
      # Scheduler usa o webserver para API
      AIRFLOW__API__BASE_URL: http://airflow3-api-server:8080
    command: ["bash","-c","exec airflow scheduler"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    restart: unless-stopped

  airflow3-triggerer:
    <<: *airflow-common
    environment:
      <<: *airflow-common-env
      # Triggerer usa o webserver para API
      AIRFLOW__API__BASE_URL: http://airflow3-api-server:8080
    command: ["bash","-c","exec airflow triggerer"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    restart: unless-stopped

  airflow3-dag-processor:
    <<: *airflow-common
    environment:
      <<: *airflow-common-env
      # DAG processor usa o webserver para API
      AIRFLOW__API__BASE_URL: http://airflow3-api-server:8080
    command: ["bash","-c","exec airflow dag-processor"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    restart: unless-stopped

  airflow3-worker:
    image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:3.0.6}
    environment:
      # Worker para Airflow 3 - SEM acesso direto ao DB
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis3:6379/0
      # Worker usa APENAS Task Execution API
      AIRFLOW__TASK_EXECUTION__ENDPOINT_URL: http://airflow3-api-server:8080/execution
      AIRFLOW__API__BASE_URL: http://airflow3-api-server:8080
      # Configurações básicas
      AIRFLOW__CORE__DEFAULT_TIMEZONE: ${TZ:-America/Sao_Paulo}
      TZ: ${TZ:-America/Sao_Paulo}
      AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
      NO_PROXY: ${NO_PROXY:-localhost,127.0.0.1,airflow3-api-server,postgres3,redis3}
      _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-apache-airflow-providers-postgres apache-airflow-providers-fab}
    user: "${AIRFLOW_UID:-50000}:0"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: ["bash","-c","exec airflow celery worker"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    restart: unless-stopped

  flower3:
    <<: *airflow-common
    # Flower não precisa do API__BASE_URL
    command: ["bash","-c","exec airflow celery flower"]
    depends_on:
      airflow3-init:
        condition: service_completed_successfully
    restart: unless-stopped

volumes:
  postgres3-data: